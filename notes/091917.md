# CSCI 1103 Computer Science I Honors

### Fall 2017

---

## Lecture Notes
## Week 4, Meeting 1

**Topics:**

    1. Learning from List.rev & List.mem -- more on Repetition & Work
    2. A Simple Application

---

## 1. Learning from rev & mem — more on Repetition & Work

Last time we wrote our own versions of the `List.append ` and `List.rev` functions:

```ocaml
(* append : : 'a list -> 'a list -> 'a list
*)
let rec append xs ys =
  match xs with
  | [] -> ys
  | z :: zs -> z :: append zs ys
  
(* rev : 'a list -> 'a list
*)  
let rec rev xs =
  match xs with
  | [] -> []
  | z :: zs -> append (rev zs) [z]
```

Simplification of `rev [1; 2; 3]` skipping many steps as we'll feel free to do from now on:

```ocaml
rev [1; 2; 3] -> 
  append (rev [2; 3]) [1] ->
  append (append (rev [3]) [2]) [1] ->
  append (append (append (rev []) [3]) [2]) [1] ->
  append (append (append [] [3]) [2]) [1] -> (* 3 calls to append stacked up for xs of length 3 *)
  append (append [3] [2]) [1] ->             (* 2 calls remaining *)
  append [3; 2] [1] ->                       (* 1 to go *)
  [3; 2; 1]
```

As we discussed last time, the `append` function performs an amount of work that is *linear* in the length of it's first argument. That is, when called with a first argument containing N elements, it does an amount of work proportional N. The amount of work `append` performs is independent of the number of elements in its second argument.

Let's say that our `rev` function is called with a list containing M elements. Then, as can be seen from the above trace, `rev` calls `append` M times. 

- The innermost call provides `append` a first argument of length 0, 
- the next innermost call provides `append` a first argument of length 1,
- the final (outermost) call provides `append` a first argument of length M - 1.

So in sum, `rev` makes a linear number of calls to the `append` function which does a linear amount of work. Putting it all together, when `rev` is called with a list of length M, it performs work proportional to
$$
0 + 1 + 2 + \ldots + (M - 1) \approx M(M + 1)/2
$$
This is to say, that this simple-minded definition of `rev` performs an amount work proportional to $M^2$, i.e., the work performed is *quadratic* in the number of elements in the input list. For small M the presence of the exponent 2 doesn't matter too much but for larger M, say $M = 10^6$ (which is not all that large) this version of `rev` would require on the order of $10^{12}$ — a ***trillion*** steps. If your computer can do one billion steps per second, this would require 1000 seconds, roughly 16 minutes. This isn't very good for a list reversal algorithm.

#### Efficient List Reversal

We'll cut to the chase on finding a better list reversal algorithm: we'll write a new version of `rev` that accepts *two inputs* rather than one — the second input will be the basis of the final answer:

```ocaml
(* rev : 'a list -> 'a list -> 'a list
*)
let rec rev xs answer =
  match xs with
  | [] -> answer
  | z :: zs -> rev zs (z :: anwer)
```

A trace of the call `rev [1; 2; 3] []` to our new version shows a computation with a different shape:

```ocaml
rev [1; 2; 3] [] ->
  rev [2; 3] [1] ->
  rev [3] [2; 1] ->
  rev [] [3; 2; 1] ->
  [3; 2; 1]
```

When called as in `rev xs []` where `xs` is a list with $M$ elements, `rev` is called a total of $M + 1$ times. But this version isn't  calling `append` each time through as the previous simple-minded version did. This two-argument version performs work proportional to M. I.e., it is *linear* in M. For an input list of size $10^6$, this algorithm does on the order of $10^6$ simplification steps — a "pay as you go" amount of work.

> **Tail Recursion and Memory Efficiency** The new version of `rev` improves on the old one in another important respect — it turns out that in addition to performing fewer simplification steps, the new version also uses less of your computer's memory. The old version wasn't just making M calls to `append`, it was *stacking them up* — the expressions grew wider and wider from one line to the next. As we'll discuss later, this required the computer to use memory to remember the context for each of the $M$ pending calls. The inefficient version required storage space proportional to $M$. (So it was quadratic in time and linear in space.)
>
> The trace of the call of the improved version of `rev` above shows that the new version isn't stacking up calls — the expressions are not growing wider from one line to the next. This space-efficient shape of recursion has a name — *tail recursion*. We'll return to this important topic later on.

#### Restoring Modularity

The new two-argument version of `rev` is certainly an improvement, but this version too can be improved. As a matter of packaging or modularity, we'd prefer that our `rev` function require only one input — the list we want reversed.  We can use a `let-in` expression to tuck this two-argument version (renamed `repeat` below) inside the definition of a one-argument wrapper version as follows:

```ocaml
(* rev : 'a list -> 'a list
*)
let rev xs =
  let rec repeat xs answer =                (* NB: the repeat function is hidden within rev *)
    match xs with
    | [] -> answer
    | z :: zs -> repeat zs (z :: answer)
  in
  repeat xs []
```

This is a common idiom that can be used in modularizing efficient code.

```ocaml
(* fibo : int -> int                   -- correct and with good modularity but wildly inefficient
*)
let rec fibo n =
  match n < 3 with
  | true  -> 1
  | false -> fibo (n - 1) + fibo (n - 2)
  
(* fibo : int -> int -> int -> int     -- correct and efficient but with poor modularity
*)
let rec fibo n a b =
  match n = 1 with
  | true  -> a
  | false -> fastFibo (n - 1) b (a + b)
  
(* fibo : int -> int                   -- correct, efficient and modular
*)
let fibo n =
  let rec repeat n a b =
    match n = 1 with
    | true  -> a
    | false -> repeat (n - 1) b (a + b)
  in
  repeat n 1 1
```

The idea of making a more efficient version of a function by adding arguments while preserving the natural interface applies broadly. As a last example, a less efficient and a more efficient version of a function for computing $N!$:

```ocaml
(* fact : int -> int           -- correct and modular but less efficient use of memory
*)
let rec fact n =
  match n = 0 with
  | true  -> 1
  | false -> n * fact (n - 1)
  
(* fact : int -> int           -- correct and modular with more efficient use of memory
*)
let fact n =
  let rec loop n answer =
    match n = 0 with
    | true  -> answer
    | false -> loop (n - 1) (n * answer)
  in
  loop n 1
```

> In slogan form: the less memory efficient versions do their work on the way out while the more memory efficient tail-recursive versions do their work on the way in.

**Exercise**: Write a more space efficient version of the follow `power : int -> int -> int` function:

```ocaml
(* power : int -> int -> int
*)
let rec power m n =
  match n = 0 with
  | true  -> 1
  | false -> m * power m (n - 1)
```

#### Learning from List.mem

Given some item `x` can it be found in a list `xs`? The `List.mem` function computes the answer.

```ocaml
(* mem : 'a -> 'a list -> bool
*)
let rec mem x xs =
  match xs with
  | [] -> false
  | y :: ys -> (match x = y with
                | true  -> true
                | false -> mem x ys)
```

Example traces (again, skipping steps) of `mem 2 [1; 2; 3; 4; 5; 6]` and `mem 12 [1; 2; 3; 4; 5; 6]` 

```ocaml
mem 2 [1; 2; 3; 4; 5; 6] ->
  mem 2 [2; 3; 4; 5; 6] ->
  true                                  (* answer found in 2 (large) steps *)
  
mem 12 [1; 2; 3; 4; 5; 6] ->
  mem 12 [2; 3; 4; 5; 6] ->
  mem 12 [3; 4; 5; 6] ->
  mem 12 [4; 5; 6] ->
  mem 12 [5; 6] ->
  mem 12 [6] ->
  mem 12 [] ->
  false                                 (* answer found in 7 (large) steps *)
```

The `mem` function illustrates an important point: when asking how much work `List.length` or `List.append` did, we learned that the answer depended entirely on the length of the input list. In asking how much work `mem` does the answer depends not only on the length of the input list but also on the elements in the list. Let's say the list `xs` has N elements. The item `x` is sought by a left-to-right scan through `xs`. Once the item sought is found, the boolean value `true` is returned and the rest of the list is ignored. It's only when the item isn't in the list or is the rightmost element of the list that all N items in `xs` are inspected.

The point here is that when we're considering the amount of work performed by a function, we can consider two main cases:

1. The **worst case** — assuming the worst possible input data, how much work is performed?
2. The **average case** — assuming the entire possible range of input data, how much work is performed?

For `List.length` and `List.append` the worst and the average cases required the same number of steps. For `List.mem` the worst case is $N$ steps. For the average case, well sometimes `x` will be on the left and found right away, sometimes `x` won't be found at all. So on average we would expect that `x` would be found in the middle of the list, requiring $N/2$ steps. 

For large $N$ it turns out that $N$ and $N/2$ amount to pretty much the same amount of work. But the point here is to introduce the distinction between worst and average cases. If we're designing real-time mission critical software, say controlling an airplane's wing flap, we're going to be interested in the worst case analysis. If we're designing an algorithm that looks up credit card information, we're probably more interested in the average case analysis.

### 2. Application : Tracking Soccer Goals	

Let's say we're tracking goals scored by players in the *Union of* *European Football* *Associations* (UEFA). It's natural to think that we might store this information in a list of some sort. Let's use a simple minded representation:

```ocaml
type player = {name : string; goals : int list}
```

The `goals` field is a list recording the number of goals scored in each game. For example we might have

```ocaml
let players = [ {name = "Messier"; goals = [0; 1; 0; 1; 2; 2; 0]}
              ; {name = "Neymar";  goals = [1; 1; 1; 0; 2; 1; 3; 0]}
              (* ... *)
              ; {name = "Muller";  goals = [1; 0; 2]}
              ]
```

Lets say the winner is the player with the largest average goals and let's assume a non-empty list of players. We write

```ocaml
type player = {name : string; goals : int list}
type playerAverage = {name : string; average : float}

(* findWinner : playerAverage -> playerAverage list -> string
*)
let rec findWinner best others =
  match others with
  | [] -> best.name
  | player :: players ->
    (match best.average >= player.average with
     | true  -> findWinner best players
     | false -> findWinner player players)

(* sum : int list -> float
*)
let rec sum goals =
  match goals with
  | [] -> 0.0
  | goal :: goals -> (float goal) +. sum goals

(* average : player -> playerAverage
*)
let average player = 
  let ave = (sum player.goals) /. (float (List.length player.goals))
  in
  {name = player.name; average = ave}

(* averages : player list -> playerAverage list
*)
let rec averages players =
  match players with
  | [] -> []
  | player :: players -> (average player) :: averages players
  
(* winner : player list -> string
*)
let winner players =
  let averages = averages players
  in
  findWinner (List.hd averages) (List.tl averages)
```